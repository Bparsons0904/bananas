# PostgreSQL Configuration for Bananas Framework Testing
# Optimized for: 4GB RAM, 8 CPU cores, SSD storage
# Target: High-performance load testing and benchmarking

# -----------------------------
# CONNECTIONS AND AUTHENTICATION
# -----------------------------

max_connections = 200
# Support 6 frameworks + multiple clients + connection pooling
# Each framework may have 20-30 concurrent connections during load testing

# -----------------------------
# MEMORY CONFIGURATION
# -----------------------------

# Shared Memory (25% of total RAM for dedicated DB server)
shared_buffers = 1GB
# Main PostgreSQL cache - critical for performance

# Query Planning
effective_cache_size = 3GB
# Tells planner about available OS cache (75% of 4GB RAM)
# Helps optimizer make better decisions about index usage

# Per-Operation Memory
work_mem = 16MB
# Memory per sort/hash operation (shared_buffers / max_connections)
# 1GB / 200 connections ≈ 5MB, increased to 16MB for complex queries
# Total possible usage: 16MB × 200 = 3.2GB (monitor this!)

# Maintenance Operations
maintenance_work_mem = 512MB
# For VACUUM, CREATE INDEX, ALTER TABLE operations
# Can be higher since only a few maintenance ops run concurrently

# Hash Operations
hash_mem_multiplier = 2
# Allows hash tables to use 2x work_mem (32MB)

# -----------------------------
# PARALLELISM (8 CPU cores available)
# -----------------------------

max_worker_processes = 8
# Total background workers (matches CPU cores)

max_parallel_workers = 6
# Workers available for parallel queries (leave 2 cores for other tasks)

max_parallel_workers_per_gather = 4
# Workers per parallel operation (increased from default 2)

max_parallel_maintenance_workers = 4
# For parallel CREATE INDEX, VACUUM

# Enable parallel query for smaller tables
min_parallel_table_scan_size = 8MB
min_parallel_index_scan_size = 512kB

# -----------------------------
# WRITE-AHEAD LOG (WAL)
# -----------------------------

wal_buffers = 16MB
# WAL buffer size (default is -1 which auto-tunes to 3% of shared_buffers)
# Explicit value for consistency

# Checkpoints
checkpoint_timeout = 15min
# Time between checkpoints (default is 5min, increased for write-heavy loads)

checkpoint_completion_target = 0.9
# Spread checkpoint I/O over 90% of checkpoint interval

max_wal_size = 2GB
# Maximum WAL size before forcing checkpoint

min_wal_size = 1GB
# Minimum WAL size to keep

# -----------------------------
# QUERY PLANNER
# -----------------------------

# SSD Optimization (critical for SSDs!)
random_page_cost = 1.1
# Default is 4.0 for HDDs, SSDs should be 1.1-1.5
# This dramatically changes query plans to favor index scans

seq_page_cost = 1.0
# Sequential scan cost (baseline)

# Statistics
default_statistics_target = 100
# Number of histogram bins for ANALYZE (default 100 is fine)
# Increase to 200-500 for very large tables if needed

# Parallelism costs (encourage parallel queries)
parallel_setup_cost = 100
parallel_tuple_cost = 0.01

# -----------------------------
# LOGGING
# -----------------------------

# What to log
log_min_duration_statement = 1000
# Log queries slower than 1 second (adjust for benchmarking)

log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
# Detailed log prefix for debugging

log_checkpoints = on
# Log checkpoint activity (useful for tuning)

log_connections = off
# Disable in production (too noisy with 200 connections)

log_disconnections = off

log_lock_waits = on
# Log slow lock acquisitions (useful for concurrency debugging)

log_temp_files = 0
# Log all temp file usage (helps identify queries needing more work_mem)

# -----------------------------
# AUTOVACUUM (Important for high-write loads)
# -----------------------------

autovacuum = on
autovacuum_max_workers = 3
# Parallel autovacuum workers

autovacuum_naptime = 30s
# Check for vacuum every 30 seconds (more frequent for write-heavy)

# Aggressive autovacuum for high-throughput
autovacuum_vacuum_scale_factor = 0.1
# Vacuum when 10% of table is dead tuples (default 0.2)

autovacuum_analyze_scale_factor = 0.05
# Analyze when 5% of table changes (default 0.1)

# -----------------------------
# CLIENT CONNECTION DEFAULTS
# -----------------------------

# Locale
lc_messages = 'C'
lc_monetary = 'C'
lc_numeric = 'C'
lc_time = 'C'

# Timezone
timezone = 'UTC'

# -----------------------------
# PERFORMANCE MONITORING
# -----------------------------

shared_preload_libraries = 'pg_stat_statements'
# Track query statistics (useful for benchmarking)

pg_stat_statements.max = 10000
pg_stat_statements.track = all

# Track I/O timing (helps identify slow queries)
track_io_timing = on
track_functions = pl
track_activity_query_size = 2048

# -----------------------------
# NOTES FOR TUNING
# -----------------------------

# Monitor these metrics during load testing:
# 1. Temp file creation (increase work_mem if excessive)
# 2. Checkpoint frequency (adjust max_wal_size/checkpoint_timeout)
# 3. Connection pool utilization (adjust max_connections)
# 4. Cache hit ratio (shared_buffers effectiveness)
# 5. Lock waits (indicates concurrency issues)
#
# Useful queries:
# - SELECT * FROM pg_stat_database;
# - SELECT * FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 20;
# - SELECT * FROM pg_stat_bgwriter;
